{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Geopandas plotting vector data\n",
    "\n",
    "DATE: 11 June 2020, 18:00 - 21:00 UTC\n",
    "\n",
    "AUDIENCE: Intermediate\n",
    "\n",
    "INSTRUCTOR: Martin Bentley, Digital Geoscientist, [Agile](https://agilescientific.com/)\n",
    "\n",
    "Not all the data that we want to deal with is simply numeric. Much of it will need to be located in space as well. Luckily, there are numerous tools to handle this sort of data. For this notebook, we will focus on vector data. This is data consisting of points, lines and polygons, not gridded data. The tutorials by Leo Uieda and Joe Kington deal more with raster data and should be a good complement to this tutorial. \n",
    "\n",
    "There are a number of common spatial tasks that are often done in GIS software, such as adding buffers to data, or manipulating and creating geometries. This notebook is focused more on the basics of using existing data and plotting it, but not making many changes specific to spatial data.\n",
    "\n",
    "#### Prerequisites\n",
    "\n",
    "You should be reasonably comfortable with `pandas` and `matplotlib.pyplot`.\n",
    "\n",
    "Beyond that, this is aimed at relative beginners to working with spatial data.\n",
    "\n",
    "#### A Note on Shapefile\n",
    "\n",
    "Shapefiles are a common file format used when sharing and storing georeferenced data. A single shapefile has a number of components that are required for it to work correctly.\n",
    "These are mandatory:\n",
    "- `<name>.shp` the feature geometry.\n",
    "- `<name>.shx` is the shape index.\n",
    "- `<name>.dbx` contains the attributes in columns, for each feature.\n",
    "\n",
    "There are a number of additional files that may also be present, of which these are the most common (in the author's experience).\n",
    "- `<name>.prj` is the projection of the data.\n",
    "- `<name>.sbx` and `<name>.sbn` are a spatial index.\n",
    "- `<name>.shp.xml` is a metadata file.\n",
    "\n",
    "While shapefiles are very common on desktop systems, they tend not to be used present data on the web, although they are often offered as a download option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas and Geopandas\n",
    "\n",
    "Pandas gives us access to a data structure called a DataFrame, which is very well suited for the sort of data that is usually in spreadsheets, with rows and columns. Geopandas is an expansion of that, to allow for the data to be geographically located in a sensible way. It does this by adding a `geometry` column, a , and adding some methods for some spatially useful tests, while still allowing the usual `DataFrame` methods from pandas.\n",
    "\n",
    "In addition, we will use `cartopy` to handle projections. `mapclassify` is optional, but allows easy binning of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cartopy.crs as ccrs\n",
    "import geopandas as gpd\n",
    "import mapclassify as mc\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a geodataframe\n",
    "\n",
    "Loading a shapefile (or a number of other formats) is as simple as calling `read_file` with the right location.\n",
    "\n",
    "Geopandas uses `fiona` in the background, so anything that can be handled by `fiona` can be handled with geopandas. Note that some formats can be read, but not written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../data/cleaned/offshore_wells_2011_Geographic_NAD27.shp'\n",
    "\n",
    "well_locations = gpd.read_file(fname)\n",
    "well_locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load data as a standard DataFrame and convert it by using any existing geometry that we know about.\n",
    "\n",
    "We will load up some data available regarding issues identified at artisinal mines in Zimbabwe by the International Peace Information Service ([IPIS](http://ipisresearch.be/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../data/zwe_mines_curated_all_opendata_p_ipis.csv'\n",
    "\n",
    "artisinal_mines = pd.read_csv(fname)\n",
    "artisinal_mines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a `geom` column in this CSV, where every point is a Well-Known Text ([WKT](https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry)) string describing the geometry. To make the geodataframe aware of this, we will use the `shapely` library (that geopandas uses under the hood)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "artisinal_mines['geom'] = artisinal_mines['geom'].apply(wkt.loads)\n",
    "mines = gpd.GeoDataFrame(artisinal_mines, geometry='geom')\n",
    "mines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not look very different, but we have now created a geodataframe from our existing dataframe. We could do something very similar with a CSV with separate columns of latitude and longitude.\n",
    "\n",
    "When creating a new geodataframe like this, we should also set the Coordinate Reference System (CRS) of the data, since geopandas does not know where the coordinates actually are on the Earth's surface. Some operations will still work, but relating one geodataframe to another is not possible. We are working with straight decimal degrees of longitude and latitude, so the WGS84 datum is a good option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mines.crs = \"EPSG:4326\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the simplest way to see how a geodataframe differs from a standard dataframe is by simply calling the `plot` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artisinal_mines.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mines.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the geodataframe plots our coordinates, while the standard dataframe plots the numerical values according to their index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "The following should be easily possible with a working knowledge of `pandas`. Using the well dataset:\n",
    "1. Which well is the deepest? (`df.sort_values('column')` may be useful.)\n",
    "1. How many wells are operated by Canadian Superior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The deepest well is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# The deepest well is:\n",
    "well_locations.sort_values('Dpth_m').tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many well were operated by Canadian Superior?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# How many well were operated by Canadian Superior?\n",
    "len(well_locations[well_locations['Owner'] == 'Canadian Superior'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographic plots\n",
    "\n",
    "We can take a quick look at where these wells are in relation to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "well_locations.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we imported uses latitude and longitude. We can also easily import projected data, if we have it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../data/cleaned/offshore_wells_2011_UTM20_NAD83.shp'\n",
    "well_locations_utm = gpd.read_file(fname)\n",
    "# We are going to use the 'Spud_Date' and 'Well_Termi' column for some stuff, so we will turn it into a proper datetime column\n",
    "well_locations_utm['Spud_Date'] = pd.to_datetime(well_locations_utm['Spud_Date'])\n",
    "well_locations_utm['Well_End'] = pd.to_datetime(well_locations_utm['Well_End'])\n",
    "well_locations_utm.replace('None', np.NaN, inplace=True)\n",
    "well_locations_utm.plot()\n",
    "well_locations_utm.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the axes are completely different between the two datasets. We can therefore not plot these two datasets in the same plot unless we use the same coordinate reference system. `cartopy` is the tool we will use to do this.\n",
    "\n",
    "First, let us see what CRS the different datasets have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Wells: {well_locations.crs}\\nWells (UTM): {well_locations_utm.crs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to plot the two datasets on the same plot, then they need to use the same CRS. One of the easiest ways is by using EPSG codes and the `to_crs` method. [epsg.io](https://epsg.io) and [spatialreference.org](https://spatialreference.org) are good places to find a suitable EPSG code for your data if you are not sure how the CRS relates to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "well_locations_utm_reproj = well_locations_utm.to_crs(epsg=\"4326\")\n",
    "ax = well_locations_utm_reproj.plot(markersize=15)\n",
    "well_locations.plot(ax=ax, color='red', markersize=5, alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that these datasets now plot on top of each other, as they should."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Styling\n",
    "\n",
    "Just plotting these points on their does not tell us very much, so we should style the data to show us what is happening. We will classify the data by total depth of each well, breaking the column into 6 bins with a natural break as the upper and lower bound.\n",
    "\n",
    "We do this by using the `scheme` parameter which will be used in the background by MapClassify to bin the values of a column. A number of binning options are available, such as NaturalBreaks, Quantiles, StdMean, Percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "well_locations_utm.plot(column='Dpth_m',\n",
    "                        scheme='Percentiles', k=6,\n",
    "                        legend=True,\n",
    "                        markersize=10, cmap='cividis_r', figsize=(10,10))#.legend(bbox_to_anchor=(2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scheme` keyword passes through to `mapclassify`, and only makes sense for some data. In other cases, we can just rely on the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "well_locations_utm.plot(column='Well_Type', legend=True,\n",
    "                        markersize=10, cmap='Set1',\n",
    "                        figsize=(10,10))#.legend(bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also be interested in only a section of the data within certain extents, such as the dense cluster south-east of centre. Geopandas offers a `cx` method for a coordinate index which can be used for slicing based on coordinate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "main_field = well_locations_utm.cx[650000:800000, 4825000:4925000]\n",
    "print(main_field.shape)\n",
    "main_field.plot(column='Owner', legend=True, markersize=15, cmap='tab20', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "The data contains columns for the start and end of when a well was active.\n",
    "\n",
    "1. Which well was operating for the longest time and how long was this? (Hint: use the `datetime` columns from earlier ('Spud_Date' and 'Well_End'). A useful pattern is `df.loc[df['column'] == value]`.)\n",
    "2. Plot a histogram of the days of operation for the wells in the dataset. You may need to drop invalid data (where some columns are NaN or NaT).\n",
    "3. Using the above histogram to determine a suitable cut-off, is there an area of the field that has wells that were in operation for longer than others? (Hint: you might want to extract a useful time interval from a `Series` of `timedelta`s to plot.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which well was operating for the longest time and how long was this?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Which well was operating for the longest time and how long was this?\n",
    "well_locations_utm['Operating'] = well_locations_utm['Well_End'] - well_locations_utm['Spud_Date']\n",
    "well_locations_utm[well_locations_utm['Operating'] == well_locations_utm['Operating'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the days of operation for the wells in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot a histogram of the days of operation for the wells in the dataset.\n",
    "well_locations_utm['Operating'].dt.days.plot(kind='hist', bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the above histogram to determine a suitable cut-off, is there an area of the field that has\n",
    "# wells that were in operation for longer than others?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Using the above histogram to determine a suitable cut-off, is there an area of the field that has\n",
    "# wells that were in operation for longer than others?\n",
    "\n",
    "#well_locations_utm['Operating_Days'] = well_locations_utm[well_locations_utm['Operating'].dt.days.notna() == True]\n",
    "well_locations_utm['Operating_Days'] = well_locations_utm['Operating'].dt.days\n",
    "long_wells = well_locations_utm[well_locations_utm['Operating'].dt.days > 150]\n",
    "base = well_locations_utm.plot(color='grey', figsize=(10,10), markersize=8)\n",
    "long_wells.plot(column='Operating_Days', scheme='Quantiles',\n",
    "                cmap='viridis', alpha=0.9,\n",
    "                ax=base, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving geodataframes\n",
    "\n",
    "While we can create maps and similar things in geopandas, sometimes we want to use files in something else. Geopandas, uses `fiona` in the background to read and write files. If we want this geodataframe as a GeoJSON file, for example, this is easily done by using the correct argument to the `driver` parameter. (Note that GeoJSON only accepts the WGS84 datum, so I am reprojecting the geodataframe first.)\n",
    "\n",
    "By default, without an explicit driver, `to_file` will create a Shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "fname = '../data/geojson-offshore_wells_Geographic_NAD27.geojson'\n",
    "well_locations.to_crs(epsg=4326).to_file(fname, driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing this to a GML file (a flavour of XML) is as simple as changing the driver parameter appropriately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "fname = '../data/gml-offshore_wells_Geographic_NAD27.gml'\n",
    "well_locations.to_file(fname, driver='GML')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<img src=\"https://avatars1.githubusercontent.com/u/1692321?v=3&s=200\" style=\"float:center\" width=\"40px\" />\n",
    "<p><center>© 2020 <a href=\"http://www.agilegeoscience.com/\">Agile Geoscience</a> — <a href=\"https://creativecommons.org/licenses/by/4.0/\">CC-BY</a></center></p>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}